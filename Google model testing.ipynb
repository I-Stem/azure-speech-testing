{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python2.7/site-packages/cryptography/hazmat/primitives/constant_time.py:26: CryptographyDeprecationWarning: Support for your Python version is deprecated. The next version of cryptography will remove support. Please upgrade to a 2.7.x release that supports hmac.compare_digest as soon as possible.\n",
      "  utils.PersistentlyDeprecated2018,\n",
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already up-to-date: google-cloud-speech in /anaconda3/lib/python2.7/site-packages (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /anaconda3/lib/python2.7/site-packages (from google-cloud-speech) (1.14.2)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.19.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2018.5)\n",
      "Requirement already satisfied, skipping upgrade: futures>=3.2.0; python_version < \"3.2\" in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (40.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /anaconda3/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda3/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.24,>=1.21.1 in /anaconda3/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /anaconda3/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /anaconda3/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (0.2.6)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /anaconda3/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: enum34>=1.0.4 in /anaconda3/lib/python2.7/site-packages (from grpcio<2.0dev,>=1.8.2; extra == \"grpc\"->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.1.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /anaconda3/lib/python2.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (0.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GOOGLE_APPLICATION_CREDENTIALS=\"/Users/anshul/Desktop/ISTEM/My First Project-ebb8cc0917d0.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer1(ref, hyp ,debug=False):\n",
    "    ref=ref.lower()\n",
    "    hyp=hyp.lower()\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "\n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "\n",
    "    DEL_PENALTY=1 # Tact\n",
    "    INS_PENALTY=1 # Tact\n",
    "    SUB_PENALTY=1 # Tact\n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "\n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "\n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "\n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\".\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    if debug:\n",
    "        lines = list(reversed(lines))\n",
    "        for i,line in enumerate(lines):\n",
    "            if(line.startswith('.')):\n",
    "                if(i-1 > 0):\n",
    "                    if(not lines[i-1].startswith('.')):\n",
    "                        print(line)\n",
    "                        continue\n",
    "                if(i+1 < len(lines)):\n",
    "                    if(lines[i+1].startswith('.')):continue\n",
    "            print(line)\n",
    "        print(\"Ncor \" + str(numCor))\n",
    "        print(\"Nsub \" + str(numSub))\n",
    "        print(\"Ndel \" + str(numDel))\n",
    "        print(\"Nins \" + str(numIns))\n",
    "    return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "    return {'WER':wer_result, 'Cor':numCor, 'Sub':numSub, 'Ins':numIns, 'Del':numDel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 500kB/s ta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/anshul/Library/Caches/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "!pip3 install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatized(para):\n",
    "    para=para.lower()\n",
    "    def get_wordnet_pos(word):\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final=''\n",
    "    sent_text = nltk.sent_tokenize(para) \n",
    "    for sentence in sent_text:\n",
    "        x=([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])\n",
    "        x=\" \".join(x)+' '\n",
    "        final=final+x\n",
    "    return(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-cloud-speech in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-cloud-speech) (1.14.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (40.8.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.20.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (0.2.6)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.25.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from rsa>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (0.4.7)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting google-cloud-bigquery\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/ae/d204d8fa443d8cb7b4d34861baadd72edc8a65b1b217b597790158408455/google_cloud_bigquery-1.19.0-py2.py3-none-any.whl (149kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 623kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.0.3 (from google-cloud-bigquery)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/f0/084f598629db8e6ec3627688723875cdb03637acb6d86999bb105a71df64/google_cloud_core-1.0.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-cloud-bigquery) (3.7.1)\n",
      "Collecting google-resumable-media>=0.3.1 (from google-cloud-bigquery)\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/5e/cebf1313c256e9e7e1ad730862e76b6a0953b720ae1be116aa2d5b9f5107/google_resumable_media-0.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.14.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (1.14.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.6.0->google-cloud-bigquery) (40.8.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.6.0->google-cloud-bigquery) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (0.2.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (1.25.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from rsa>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery) (0.4.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: google-cloud-core, google-resumable-media, google-cloud-bigquery\n",
      "Successfully installed google-cloud-bigquery-1.19.0 google-cloud-core-1.0.3 google-resumable-media-0.4.0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade google-cloud-speech\n",
    "!pip3 install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud.bigquery.client import Client\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/anshul/Desktop/ISTEM/My First Project-ebb8cc0917d0.json\"\n",
    "bq_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1\n",
    "from google.cloud.speech_v1 import enums\n",
    "\n",
    "\n",
    "def sample_long_running_recognize(audio):\n",
    "    \"\"\"\n",
    "    Transcribe long audio file from Cloud Storage using asynchronous speech\n",
    "    recognition\n",
    "\n",
    "    Args:\n",
    "      storage_uri URI for audio file in Cloud Storage, e.g. gs://[BUCKET]/[FILE]\n",
    "    \"\"\"\n",
    "\n",
    "    client = speech_v1.SpeechClient()\n",
    "    #client = speech.SpeechClient()\n",
    "\n",
    "    # storage_uri = 'gs://cloud-samples-data/speech/brooklyn_bridge.raw'\n",
    "\n",
    "    # Sample rate in Hertz of the audio data sent\n",
    "    sample_rate_hertz = 16000\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-US\"\n",
    "\n",
    "    # Encoding of audio data sent. This sample sets this explicitly.\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = enums.RecognitionConfig.AudioEncoding.FLAC\n",
    "    config = {\n",
    "        \"sample_rate_hertz\": sample_rate_hertz,\n",
    "        \"language_code\": language_code,\n",
    "        \"encoding\": encoding,\n",
    "    }\n",
    "    #audio = {\"uri\": storage_uri}\n",
    "\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "\n",
    "    print(u\"Waiting for operation to complete...\")\n",
    "    response = operation.result()\n",
    "    #print(response.results)\n",
    "    res = ''\n",
    "    for result in response.results:\n",
    "        # First alternative is the most probable result\n",
    "        alternative = result.alternatives[0]\n",
    "       \n",
    "        #print(u\"Transcript: {}\".format(alternative.transcript))\n",
    "        res += alternative.transcript\n",
    "        \n",
    "    return res\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio loaded\n",
      "Waiting for operation to complete...\n",
      "audio loaded\n",
      "Waiting for operation to complete...\n",
      "audio loaded\n",
      "Waiting for operation to complete...\n",
      "audio loaded\n",
      "Waiting for operation to complete...\n",
      "audio loaded\n",
      "Waiting for operation to complete...\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "\n",
    "# Pass the audio data to an encoding function.\n",
    "def encode_audio(audio):\n",
    "  audio_content = audio.read()\n",
    "  return base64.b64encode(audio_content)\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "#enter path for audio files to be tested\n",
    "path='/Users/anshul/Desktop/ISTEM/azure-speech-testing/'\n",
    "#enter name of audio files to be tested\n",
    "uris=[#'gs://speechtotext276/Kiran_Bedi_How_I_remade_one_of_Indias_toughest_prisonst0.flac',\n",
    "      #'gs://speechtotext276/chem0.flac',\n",
    "      #'gs://speechtotext276/chem1.flac',\n",
    "      #'gs://speechtotext276/edu1.flac',\n",
    "      'gs://speechtotext276/edu2.flac',\n",
    "      'gs://speechtotext276/b0.flac',\n",
    "      'gs://speechtotext276/b1.flac',\n",
    "      'gs://speechtotext276/b2.flac',\n",
    "      'gs://speechtotext276/Thoughts_on_humanity_fame_and_love_Shah_Rukh_Khant1.flac'\n",
    "      \n",
    "     ]\n",
    "for uri in uris:\n",
    "    audio = {\"uri\": uri}\n",
    "    print(uri,'audio loaded')\n",
    "    res = sample_long_running_recognize(audio)\n",
    "    \n",
    "    file = open('./auds/subs/'+uri[21:-5]+'.txt',\"w\")#write mode \n",
    "    file.write(res) \n",
    "    file.close()\n",
    "    print('saved txt file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./auds/subs/'+uri[21:-4]+'.txt',\"w\")#write mode \n",
    "file.write(res) \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "transcripts.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\tTranslator: Riaki Ponit Reviewer: Denise RQ I\\'m here to talk to you about Indian education, higher education in particular. But I\\'m actually going to start with demography. How many of you here are under 35? OK, that seems pretty representative of the country; 65% of India is under 35. How many of you are under 25? Then you are not representing because half of the Indian population is pretty much under 25. We are an amazingly young country. In fact, if you just take the age group from 10 to 19, there are 226 million Indians, poised, in other words, to enter higher education, going through school and ready for higher education. This is amazing because it\\'s happening at the time when the rest of the world is aging. If you look at the average age in India today, it\\'s 28. Of course, don\\'t ask about the gap - since we heard about gaps - between the average age of the Indian person and of the Indian cabinet. I think we hold the world record for that. But, that\\'s another TED talk, right? But what you\\'ve got with the average ages at a time when the rest of the world is changing, is that by 2020, the average age in Japan is going to be 47, in China it\\'s going to be heading well past 40, Europe, 46, the United States, beautiful US, also 40, and India\\'s average age is going to be 29. So we are potentially the people who are youthful, productive, dynamic, young population, ready to work, and transform the world, the kinds of role that, say, China played in the last generation could be ours in the next. In fact, International Labor Organization has worked out that by 2020, we\\'ll have 160 million people in the age group of starting work, - 20 to 24 is what they calculate - and China will only have 94 million, at the same time. So we really are poised to do that. But, and by the way, other countries will have a serious deficit that\\'s estimated that the US will have 17 million short in terms of how many people they need of working age. We, in India, have the people. But do we have the ability to equip the people to take advantage of this, to be the workforce of the work engine for the world? See, if we get it right, we educate and train them, we really transform not just our own economy and our society, but the world. If we get it wrong, the demographic dividend that I\\'m talking about becomes a demographic disaster. Because, we\\'ve already seen in 165 of our 625 districts what happens when unemployed, frustrated, undereducated young man become prey to the blandishments of the Maoists and prey to the gun and the bullet. So education in our country is not just a social or economic issue, it\\'s even a national security issue.\\n1\\tWe\\'ve got equip our people to take advantage of what the 21st century offers them. This is the story in a nutshell: 4 E\\'s, Expansion with our first priority in education. Why? Because the British - and I wouldn\\'t even ask if any of you are here - left us in 1947, with a 16% literacy rate. there were only 400,000 four-lakh students in the entire country in higher education. We had 26 universities, fewer than 700 colleges. So obviously, expansion was essential; we\\'ve gone right from that 16% to 74% literacy today, we\\'ve gone from 26 universities to 650 universities, we\\'ve gone from those 400,000 students, four-lakh students, to 20 million students in higher education today, and we have 35,000 colleges as well, instead of 700 colleges we had then. So expansion has taken place. We\\'ve also had to fight for the second E of Equity. That is, including the excluded from the education, trying to reach out to the unreached, the people who didn\\'t get a fair shake in education for reasons they couldn\\'t help: gender, an obvious reason. When we had had that 16% literacy rate, do you know what the female literacy rate was? 8.9% at the time of the independence. Just one out of 11 Indian women could read and write. Caste, region, religion, all sorts people got left out of system. We had to bring them in. And that became a big challenge and a priority for education. In getting those two things more or less right, I don\\'t know how well we did on the third E, which is the E of Excellence. Obviously, you need quality. And we set about setting up institutions of great quality in our country. The IITs are a good example, in fact, it\\'s part of Jawaharlal Nehru\\'s vision that IIT in Kharagpur was established in 1956, the year I was born, and it was done on the site of a British detention center, the Hijili detention center. So a symbol of political oppression became instead a symbol of hope, of technology, of looking to the future. But, for the IITs, the IIMs, a few good institutions, I\\'m sure you could all pick your few around the country, these have tended to be islands of excellence floating on the sea of mediocrity. The average Indian higher education institution is simply not of the quality that you and I, all of us, in this audience would like to see. And that ties into the fourth E I\\'ve added to this catechism: Employability. Talk to employers, talk to CEOs, what would they tell you? That they\\'re simply not satisfied with the quality of the graduates they\\'re getting. Even in the T of TED, the technological area, engineering graduates, half a million engineering graduates a year, but if you talk to the Federation of Indian Chambers of Commerce and Industry, they did a survey and 64% of employers are not satisfied with the quality of graduates they\\'re getting. Some companies are running, essentially, re-education places, like the gigantic campus in Mysore.\\n2\\tAnd it\\\\\\'s not on the job training which big companies tend to do, it is, in fact, a full-year\\\\\\'s education for the people they\\\\\\'ve already hired, to make up for the deficiencies of what they\\\\\\'ve learned or not properly learned in the college. Now, that\\\\\\'s the scale of the challenge that we face. What are we doing about it? A great deal needs to be done. Of course, we are trying to put in kids into the system at an early age, the RTE, the Right to Education Act, if kids were out of school in the old days, it was their parents\\\\\\' fault; today, if there are out of school it\\\\\\'s a state\\\\\\'s fault. The government is committed to actually getting them an education. We\\\\\\'ve got more and more money being pumped in by the system at all levels. For example, many of you may have gone to prestigious universities; lots of people in India don\\\\\\'t. They go to state universities which are grossly under-financed. We\\\\\\'ve come up with a scheme to pump central money into the state universities, so they actually have the resources to do something with the students they have there. Money isn\\\\\\'t the whole answer. There is an entire challenge, in terms of addressing things like the gender gap - that\\\\\\'s a gap, but despite what mister... or what an earlier speaker said, we don\\\\\\'t want to embrace, right? - that we must, must overcome. Right now, women\\\\\\'s literacy is 66%, better than the 8.9, but it still means that, you know, one out of every 3 Indian women still can\\\\\\'t read and write. We have to overcome that. And we need to catch the ones who\\\\\\'ve been left out of the net: adult literacy; huge challenge. I went off to a village in Tamil Nadu, not far from Khan Jibran, but I\\\\\\'ve met women, who in their 50s and 60s, were learning to read and write. And people think sometimes what\\\\\\'s the point, some of their own family members, their husbands, think what\\\\\\'s the point. The answer is it changes their lives, it empowers them in real ways. I spoke to a woman called Chitra Mani, who proudly wrote her name in Tamil on a piece of paper. I said: \"So, what does being able to read and write mean to you?\" And she said: \"Now I can see the destination of a bus, where it\\\\\\'s going; I don\\\\\\'t need to ask somebody where that bus is going. I know where I can go. When I get to the big city of Gandhi Puram, I can read the street signs, I can find where I need to go, I don\\\\\\'t feel helpless anymore.\" That kind of empowerment is what literacy gives people in a very fundamental and real way. And we\\\\\\'re trying to do that of course, for those who\\\\\\'ve dropped out early on, in the days before we got to that 74%. Younger kids, we\\\\\\'ve got them into school now. We\\\\\\'ve something called a gross enrollment ratio, the percentage of children of a certain age, of the appropriate one for a particular level of education. But at our primary school now, our gross enrollment ratio is 116%. We\\\\\\'ve actually enrolled more kids than we thought existed at that age group, because some of the older ones are coming in too. Bad news is, as you go up the level, it starts dropping, So by the 8th grade, I\\\\\\'m afraid it\\\\\\'s down to 69%, by the 10th grade, 39%,\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Translator: Riaki Ponit Reviewer: Denise RQ I'm here to talk to you about Indian education, higher education in particular. But I'm actually going to start with demography. How many of you here are under 35? OK, that seems pretty representative of the country; 65% of India is under 35. How many of you are under 25? Then you are not representing because half of the Indian population is pretty much under 25. We are an amazingly young country. In fact, if you just take the age group from 10 to 19, there are 226 million Indians, poised, in other words, to enter higher education, going through school and ready for higher education. This is amazing because it's happening at the time when the rest of the world is aging. If you look at the average age in India today, it's 28. Of course, don't ask about the gap - since we heard about gaps - between the average age of the Indian person and of the Indian cabinet. I think we hold the world record for that. But, that's another TED talk, right? But what you've got with the average ages at a time when the rest of the world is changing, is that by 2020, the average age in Japan is going to be 47, in China it's going to be heading well past 40, Europe, 46, the United States, beautiful US, also 40, and India's average age is going to be 29. So we are potentially the people who are youthful, productive, dynamic, young population, ready to work, and transform the world, the kinds of role that, say, China played in the last generation could be ours in the next. In fact, International Labor Organization has worked out that by 2020, we'll have 160 million people in the age group of starting work, - 20 to 24 is what they calculate - and China will only have 94 million, at the same time. So we really are poised to do that. But, and by the way, other countries will have a serious deficit that's estimated that the US will have 17 million short in terms of how many people they need of working age. We, in India, have the people. But do we have the ability to equip the people to take advantage of this, to be the workforce of the work engine for the world? See, if we get it right, we educate and train them, we really transform not just our own economy and our society, but the world. If we get it wrong, the demographic dividend that I'm talking about becomes a demographic disaster. Because, we've already seen in 165 of our 625 districts what happens when unemployed, frustrated, undereducated young man become prey to the blandishments of the Maoists and prey to the gun and the bullet. So education in our country is not just a social or economic issue, it's even a national security issue.\n",
      "1 \n",
      "\n",
      "\n",
      " I'm trying to talk to you about Indian education higher education in particular but I'm actually going to stop for demography how many of you here under 35 okay that seems pretty representative of the country 65% of India is under 35 how many of you are under 25 represented because actually we have half Indian population pretty much under 25 we are an amazingly young country in fact of adjusting to eat through from 10 to 19th that I 226 million Indians poison other words to enter higher education going through school and ready for her medications right if you look at the average age in India today it's 28 of course don't ask about the Gap since we had about gaps between the average age of the Indian person and of the Indian cabinet holds the world record for that but that's that's another bad that's another another Ted talk right but what you got with this average age has a time when the rest of the weather changing so by 2020 the average age in Japan is going to be 47 in China is going to be heading well past 40 Europe 46 the United States youthful us also 40 and India's average age is going to be so we are potentially the people who are the youth for productive Dynamic young population ready to work and transform the world the kinds of rules that you tryna played in the last generation could be awesome the next track International labor organization has worked up the by 2020 wheel of 116 million people in the age group of starting work 22 24 is what they calculate and China will only have 94 million at the same time so we really are poised to do that but I meant by the other countries will have a serious deficit estimated that the US will have 17 million short in terms of how many people that need working age we have the people but do we have the ability to equip the people to take advantage of this to be the Workhorse of the engine for the world do we get it right we educate and train them we really transform not just our own economy and Society but the world if we get it wrong the demographic dividend them talking about becomes a demographic disaster because we've already seen in a hundred sixty-five about 625 districts what happens when unemployed frustrated under educated young men become prey to the blandishments of the Morris and and pray to the gun on the board education and social or economic issue it's even a national security issue we've got to equip our people to take advantage about the 21st century office now this is the story in a nutshell. expansion was our first priority in education why does the British and I won't even ask if any of you here left us in 1947 with a 16% literacy rate for black students in the entire country in higher education 26 universities 2700 colleges expansion with a central BB gun rifle at 16% to 74%. The sea today we've gone from 26 universities to 650 universities we've gone from those four hundred thousand students for black students to 20 million students in higher education today and we have we have 35000 colleges as well instead of the $700 we have them fix pensions taking place we're going to have to fight for the second day of equity that is including the excluded from education trying to reach out to the unreached the people who didn't get a fair Shake in education for reasons they couldn't help genda obvious reason when we had that 16% literacy rate you know what the female literacy rate was 8.9% of the time of Independence just one out of 11 Indian women could read and write cost Regent religion all sorts of people that left out the system we had to bring them in and that became a big Challenge and the priority for education in getting those two things more or less right I don't know how well we did on the 30 which is the CEO of Excellence of great quality in our country the IIT is that a good example in fact it's bothering his vision that the iit-kharagpur was established back in 1956 the year I was born and it was done on the site of a British Detention Center engine Center so a symbol of political oppression became instead of symbol of Hope of Technology of looking to the future but the it is Iams a few good institutions I'm sure you can all pick you up to around the country he's attended to the islands of Excellence floating on a sea of mediocrity the average Indian higher education institutions is simply not of the quality that you and I I what about in this audience would like to see that ties into the 4th either I've added to the schedule employee ability talk to employers talk to see you as what did they tell you that they simply not satisfied with the quality of the graduates are getting even though the T of Ted the technological area Engineering Graduate engineering graduates a year but if you talk for example to the Federation of Indian Chambers of Commerce and Industry they did a survey 64% of employers are not satisfied with the quality of graduates they getting some companies are running essentially re-education places the gigantic campus in my soft and it's not on the job training with big companies tend to do it is in fact really a full Year's education for the people that already hired to make up for the deficiencies of what they've learned enough probably learned in college now that's the scale of the challenge that we face what are we doing about it a great deal of course we are trying to put in kids into the system as an early age there are t the right to Education Act if kids were out of school in the old days it was their parents for today they're out of school it's a state's fault the government is committed to actually getting them in education we've got more and more money than pumpkin by the system at all levels for example many of you may have gone to prestigious universities lots of people in there don't they go to State University's which I Bruce Lee on the finance we've come up with a scheme to pump Central money into the State University so they actually have resources to do something with with the students that have that money is in the whole lot better than entire challenge in terms of addressing things like the gender gap that's a gap that despite what mr. about the speaker said we don't want to embrace right it's a gap we must must overcome right now women's literacy 66% better than the 8.9 but still means that you know what whatever III demon Stilton reading right we have to overcome that we need to catch the ones we left out to them I don't let you see you challenge I went off to UPS a village in Tamil. Not far from Candy but I met women in their 50s and 60s were learning to read and write and people think sometimes about the point some of their own family members that husbands think what's the point the answer is it changes that empowers them and I spoke to a woman go to throw money who told me proudly wrote your name in Tamil on the piece of paper and I said so what is being able to read mean and read and write mean to you and she said no I I can I can see the destination of the bus where it's going I don't need anyone to ask somebody where that buses going I know where I can go when I get to the big city of Grants you put them I can read the street signs I can find what I need to go I don't feel helpless anymore. Kind of empowerment is what literacy gives people in a very fundamental and real way and we're trying to do that of course for those who dropped out early on in the days before we got to that 74% the younger kids we've got them into school now with only go to gross enrolment ratio to percentage of children of a certain age of the age appropriate for a particular level of education but a primary school now a gross enrolment ratio is 116% then actually enrolled more kids and we thought existed that is bad news is as you go up a level it starts dropping so by the 8th grade I'm afraid down to 16 69% by the 10th grade 59% and by college all gross and Roman Reigns by 18% against the global average of 29% haven't managed to get everyone to stay in the system some of them actually me vocational training then are all going to become High Colour clock so or officials or is Officer so we need to try and catch them and get them into vocational training but how do you do that in a culture with a 3,000 years if you wanted to be a couple of the carpenter you better have an uncle or father was a cobra Carpenter because nobody else will go to teach the transmission of knowledge of tradecraft in our country has always been through the gym to one the reason why the sons of politicians tend to be politicians don't say I'm on a Bollywood movie stars same story so we need to get monster trucks when invited why is it with a country of 1.2 billion people that we should have a nationwide shortage of Mason a plumber's of certified electrician we need to get more vocational training in the system with doing that without rolling out the whole concept of community colleges that kids can go and have some academic learning lots of vocational training and the end of two years if they showed tremendous I can promise you can go back to a university if not they leave the two-year certificate and they go off and do you use for trade in a society that is clamoring for this feels so these are the times of changes that we're trying to bring about a move along but there's a change of the governmental accounting you know if you look at the need for research and Innovation you had a lot of that I'm sure in the in the course of the dental research or something which the government wants to double the amount of money spending on Research from 1% of GDP to 2% haven't had the money to pump into it yet but Innovation requires new ways of thinking I heard you had a talk about a person can I missed it but new ways of thinking means letting to think out-of-the-box letting to create a new a famous would you guard Rider Google let's Frugal Innovation and the top 20 hits with all relate to Indian inventions we've invented the world's cheapest electrocardiogram EKG the most keep a small car the top of an old that's got all these have been things invented elsewhere there be a stripped-down made more affordable for a pic of them irrelevant we need to do things that others have done before which was used to doing. Culture where the landed invented the zero remember how the Romans use to write the numerals and long strings of letters and tell an Indian thought of the idea of zero emerging from the notion of Juniata in Hindu and Buddhist thinking and that came into the zero should India which transformed level mathematics we need to think like that again we need to come up with ideas up 17% great why do we only have 2.8% of the worlds with such output coming out of our country well have some meat we need to start in the classroom get our kids just to have their heads filled full of faxing textbook materials and teachers lectures because Frankie that gives you a well-filled mind but in the year of the internet you don't need a well-filled mind you can Google find out anything you want with two clicks of the mouse what you need is a well-formed mind a mind that reacts to unfamiliar facts and details that can actually synthesize information that it hasn't started before a mine in other words that can react to the bigger examination called life with doesn't actually want to give you things you prepared for and for that you need a man that's shaped by original thinking I might teacher why the vinyl I've actually had a little experience of out-of-the-box thinking myself I wear glasses I don't need them to read I don't need them to see you folks on the front but I want to catch somebody in the back I have to look through glasses but because I hardly ever wear them I keep losing a breaking them against the wall or something they crack I put them on my lap when I get up there for somebody steps on them they break in the first three months of this year I lost all broke six pairs of glasses for a hundred and fifty years glasses have been made in one way right now joined together listen to The Hangover years that's what I find an inconvenience I take them off and he said no no no no no you will find a different way you can reimagine glasses in a way that they not going to hang over your years of the middle of this is what he did I am wearing them right now and I want to see anybody at the back I guess we'll get together like two magnets in the middle that click together and I can see you all of the back it's just a silly example perhaps but it's an example of how one can think out of the box you can things familiar objects can be sold off in ways that haven't been thought of before and that way we can move forward in the world I have no doubt that the challenges are enormous that is simply no question that here you know what country we have to become literate for there is one piece of good news 95% about 12 year olds across India can read and so the future looks good and as far as the workforce is concerned if we can get all these other pieces in place we can say to the rest of the world we're coming thank you very much \n",
      "\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/anshul/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.7/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.7/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.7/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-cd4aa57b0e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# printing the actual ground truth without any normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscripts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# printing the actual transcripts without any normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mground\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlemmatized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mground\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[a-zA-Z0-9]+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# normalizing - removing punctuations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mele\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[a-zA-Z0-9]+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscripts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ccf0e07c45c9>\u001b[0m in \u001b[0;36mlemmatized\u001b[0;34m(para)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msent_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ccf0e07c45c9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msent_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ccf0e07c45c9>\u001b[0m in \u001b[0;36mget_wordnet_pos\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m\"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         tag_dict = {\"J\": wordnet.ADJ,\n\u001b[1;32m     10\u001b[0m                 \u001b[0;34m\"N\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             AP_MODEL_LOC = 'file:' + str(\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             )\n\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/anshul/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.7/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.7/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.7/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ground_truths=[]\n",
    "vids=['A_well_educated_mind_vs_a_well_formed_mind_Dr_Shashi_Tharoor_at_TEDxGateway_2013',\n",
    "     ]\n",
    "for file in vids:\n",
    "    f= open((path+file+'_transcribed.txt'),'r')\n",
    "    w=f.readlines()\n",
    "    #print(w)\n",
    "    ground_truths.append(w)\n",
    "wers=[]\n",
    "s = ''\n",
    "for string in w:\n",
    "    s += string\n",
    "ground_truths = [s]\n",
    "for i in range(len(transcripts)):\n",
    "    ground=(ground_truths[i].split('\\t')[1])\n",
    "    print('\\n',(ground),'\\n') # printing the actual ground truth without any normalization\n",
    "    print('\\n',(transcripts[i]),'\\n') # printing the actual transcripts without any normalization\n",
    "    ground=lemmatized(ground)\n",
    "    ground=\" \".join(re.findall(\"[a-zA-Z0-9]+\", ground)) # normalizing - removing punctuations\n",
    "    ele=\" \".join(re.findall(\"[a-zA-Z0-9]+\",(lemmatized(transcripts[i])))) \n",
    "    wer1(ground,ele,True)#  comment this line if you only want the word error rate and not the debugging\n",
    "    wers.append(wer(ground,ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(vids)):\n",
    "    print(vids[i],'\\t',wers[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

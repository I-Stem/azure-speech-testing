{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python2.7/site-packages/cryptography/hazmat/primitives/constant_time.py:26: CryptographyDeprecationWarning: Support for your Python version is deprecated. The next version of cryptography will remove support. Please upgrade to a 2.7.x release that supports hmac.compare_digest as soon as possible.\n",
      "  utils.PersistentlyDeprecated2018,\n",
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Collecting google-cloud-speech\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/4f/94b8c54376384ec36dd2573d175c2be6663eb0bc165588dd807c7ab1b568/google_cloud_speech-1.2.0-py2.py3-none-any.whl (84kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 187kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-core[grpc]<2.0.0dev,>=1.14.0 (from google-cloud-speech)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e5/7059475b3013a3c75abe35015c5761735ab224eb1b129fee7c8e376e7805/google_api_core-1.14.2-py2.py3-none-any.whl (68kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.19.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2018.5)\n",
      "Requirement already satisfied, skipping upgrade: futures>=3.2.0; python_version < \"3.2\" in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.11.0)\n",
      "Collecting google-auth<2.0dev,>=0.4.0 (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 5.1MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (40.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.7.1)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech)\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /anaconda3/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /anaconda3/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda3/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.24,>=1.21.1 in /anaconda3/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.0.4)\n",
      "Collecting cachetools>=2.0.0 (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech)\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/70/e5ea8afd6d08a4b99ebfc77bd1845248d56cfcf43d11f9dc324b9580a35c/pyasn1_modules-0.2.6-py2.py3-none-any.whl (95kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 296kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting rsa>=3.1.4 (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: enum34>=1.0.4 in /anaconda3/lib/python2.7/site-packages (from grpcio<2.0dev,>=1.8.2; extra == \"grpc\"->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.1.6)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/71/8f0d444e3a74e5640a3d5d967c1c6b015da9c655f35b2d308a55d907a517/pyasn1-0.4.7-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 336kB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: googleapis-common-protos\n",
      "  Building wheel for googleapis-common-protos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/anshul/Library/Caches/pip/wheels/9e/3d/a2/1bec8bb7db80ab3216dbc33092bb7ccd0debfb8ba42b5668d5\n",
      "Successfully built googleapis-common-protos\n",
      "Installing collected packages: cachetools, pyasn1, pyasn1-modules, rsa, google-auth, googleapis-common-protos, google-api-core, google-cloud-speech\n",
      "Successfully installed cachetools-3.1.1 google-api-core-1.14.2 google-auth-1.6.3 google-cloud-speech-1.2.0 googleapis-common-protos-1.6.0 pyasn1-0.4.7 pyasn1-modules-0.2.6 rsa-4.0\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GOOGLE_APPLICATION_CREDENTIALS=\"/Users/anshul/Desktop/ISTEM/azure-speech-testing/My First Project-0c2f8b4259e1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer1(ref, hyp ,debug=False):\n",
    "    ref=ref.lower()\n",
    "    hyp=hyp.lower()\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "\n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "\n",
    "    DEL_PENALTY=1 # Tact\n",
    "    INS_PENALTY=1 # Tact\n",
    "    SUB_PENALTY=1 # Tact\n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "\n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "\n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "\n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\".\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    if debug:\n",
    "        lines = list(reversed(lines))\n",
    "        for i,line in enumerate(lines):\n",
    "            if(line.startswith('.')):\n",
    "                if(i-1 > 0):\n",
    "                    if(not lines[i-1].startswith('.')):\n",
    "                        print(line)\n",
    "                        continue\n",
    "                if(i+1 < len(lines)):\n",
    "                    if(lines[i+1].startswith('.')):continue\n",
    "            print(line)\n",
    "        print(\"Ncor \" + str(numCor))\n",
    "        print(\"Nsub \" + str(numSub))\n",
    "        print(\"Ndel \" + str(numDel))\n",
    "        print(\"Nins \" + str(numIns))\n",
    "    return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "    return {'WER':wer_result, 'Cor':numCor, 'Sub':numSub, 'Ins':numIns, 'Del':numDel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 500kB/s ta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/anshul/Library/Caches/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatized(para):\n",
    "    para=para.lower()\n",
    "    def get_wordnet_pos(word):\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final=''\n",
    "    sent_text = nltk.sent_tokenize(para) \n",
    "    for sentence in sent_text:\n",
    "        x=([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])\n",
    "        x=\" \".join(x)+' '\n",
    "        final=final+x\n",
    "    return(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# The name of the audio file to transcribe\n",
    "file_name = os.path.join(\n",
    "    os.path.dirname(__file__),\n",
    "    'resources',\n",
    "    'audio.raw')\n",
    "\n",
    "# Loads the audio into memory\n",
    "with io.open(file_name, 'rb') as audio_file:\n",
    "    content = audio_file.read()\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code='en-US')\n",
    "\n",
    "# Detects speech in the audio file\n",
    "response = client.recognize(config, audio)\n",
    "\n",
    "for result in response.results:\n",
    "    print('Transcript: {}'.format(result.alternatives[0].transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from jiwer import wer\n",
    "import numpy as np\n",
    "transcripts=[]\n",
    "#enter path for audio files to be tested\n",
    "path='C:\\\\Users\\\\eklavya\\\\istem\\\\test\\\\indian\\\\New Folder\\\\'\n",
    "#enter name of audio files to be tested\n",
    "vids=['Kiran_Bedi_How_I_remade_one_of_Indias_toughest_prisonst0',\n",
    "      'A_well_educated_mind_vs_a_well_formed_mind_Dr_Shashi_Tharoor_at_TEDxGateway_2013t1',\n",
    "      \"Thoughts_on_humanity_fame_and_love_Shah_Rukh_Khant1\",\n",
    "      \"What_makes_life_complete_Gaur_Gopal_Das_TEDxMITPt4\",\n",
    "      \"Why_is_India_so_filthy_The_Ugly_Indian_TEDxBangaloret3\" \n",
    "     ]\n",
    "for vid in vids:\n",
    "    print(vid)\n",
    "    obj1=[]\n",
    "    speech_recognize_continuous_from_file(path+vid+'.wav')\n",
    "    st=''\n",
    "    for i in obj1:\n",
    "        st=st+' '+((i.result).text)\n",
    "    transcripts.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(vids)):\n",
    "    print(vids[i],'\\t',wers[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
